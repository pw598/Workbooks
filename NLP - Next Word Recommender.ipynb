{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7238f190-8be2-42eb-a628-03f385ceb147",
   "metadata": {},
   "source": [
    "# Import Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88030b0f-af57-4826-b28b-1402c198787c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db9fbd6b-3cb6-4073-a45c-e46b5f9b352b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_number</th>\n",
       "      <th>sentence_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ASIAN EXPORTERS FEAR DAMAGE FROM U . S .- JAPA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>They told Reuter correspondents in Asian capit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>But some exporters said that while the conflic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The U . S . Has said it will impose 300 mln dl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Unofficial Japanese estimates put the impact o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_number                                      sentence_text\n",
       "0                0  ASIAN EXPORTERS FEAR DAMAGE FROM U . S .- JAPA...\n",
       "1                1  They told Reuter correspondents in Asian capit...\n",
       "2                2  But some exporters said that while the conflic...\n",
       "3                3  The U . S . Has said it will impose 300 mln dl...\n",
       "4                4  Unofficial Japanese estimates put the impact o..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sample_reuters_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b003bcd1-8973-4d37-bdac-98896ec2d67d",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db4eaec8-0575-4e5d-94f8-adf7f7b2ec9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentences_clean = []\n",
    "\n",
    "for i in df['sentence_text']:\n",
    "    i = re.sub(\"[^a-zA-Z' ]\", \"\", i) # remove everything except alphabets, ' and white spaces\n",
    "    i = i.lower()\n",
    "    sentences_clean.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "931d9be1-b437-4d65-8bd0-7e7bc03b5524",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asian exporters fear damage from u  s  japan r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>they told reuter correspondents in asian capit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>but some exporters said that while the conflic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the u  s  has said it will impose  mln dlrs of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unofficial japanese estimates put the impact o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sentences\n",
       "0  asian exporters fear damage from u  s  japan r...\n",
       "1  they told reuter correspondents in asian capit...\n",
       "2  but some exporters said that while the conflic...\n",
       "3  the u  s  has said it will impose  mln dlrs of...\n",
       "4  unofficial japanese estimates put the impact o..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.DataFrame()\n",
    "dataset['Sentences'] = sentences_clean\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e0e209-41c5-4f1a-8bad-756056f1308e",
   "metadata": {},
   "source": [
    "# Vocabulary Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43eb9c23-e170-498a-8a85-70bf09080aa5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_words = \" \".join(sentences_clean).split()\n",
    "\n",
    "words_dict = {}\n",
    "\n",
    "for word in all_words:   \n",
    "    if word in words_dict:\n",
    "        words_dict[word] = words_dict[word] + 1\n",
    "    else:\n",
    "        words_dict[word] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af1c529-22d0-4678-9367-27c772f4f278",
   "metadata": {},
   "source": [
    "# Unigrams, Bigrams, Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cd333a2-f2f6-42f3-8e7a-067fb821f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_unigram(sentence):\n",
    "    tokens = sentence.split()\n",
    "    unigram_list = []\n",
    "    for i in range(len(tokens)):\n",
    "        unigram_list.append(tokens[i:i+1])    \n",
    "    return unigram_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "852ee59a-3a1c-48a2-8691-1fd84e659531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bigram(sentence):\n",
    "    tokens = sentence.split()\n",
    "    bigram_list = []\n",
    "    for i in range(len(tokens)-1):\n",
    "        bigram_list.append(tokens[i:i+2])\n",
    "    return bigram_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c65a4f5c-b612-4b5b-aa3d-50fefdf4ea69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trigram(sentence):\n",
    "    tokens = sentence.split()\n",
    "    trigram_list = []\n",
    "    for i in range(len(tokens)-2):\n",
    "        trigram_list.append(tokens[i:i+3])\n",
    "    return trigram_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d30dcd55-42d3-4c5f-93ea-722511a480e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_unigram = []\n",
    "\n",
    "# for each sentence\n",
    "for i in range(dataset.shape[0]):\n",
    "    \n",
    "    # using the defined unigram function to create unigrams\n",
    "    final_unigram.append(create_unigram(dataset['Sentences'][i]))\n",
    "\n",
    "# adding the unigram in a seperate column in the dataset\n",
    "dataset['unigram'] = final_unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f57d1350-4d8b-4db8-ab6c-32e1df6447a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_bigram = []\n",
    "for i in range(dataset.shape[0]):\n",
    "    final_bigram.append(create_bigram(dataset['Sentences'][i]))\n",
    "\n",
    "dataset['bigram'] = final_bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88de282a-ae91-4c0b-ac25-39db1cfdf667",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>unigram</th>\n",
       "      <th>bigram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asian exporters fear damage from u  s  japan r...</td>\n",
       "      <td>[[asian], [exporters], [fear], [damage], [from...</td>\n",
       "      <td>[[asian, exporters], [exporters, fear], [fear,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>they told reuter correspondents in asian capit...</td>\n",
       "      <td>[[they], [told], [reuter], [correspondents], [...</td>\n",
       "      <td>[[they, told], [told, reuter], [reuter, corres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>but some exporters said that while the conflic...</td>\n",
       "      <td>[[but], [some], [exporters], [said], [that], [...</td>\n",
       "      <td>[[but, some], [some, exporters], [exporters, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the u  s  has said it will impose  mln dlrs of...</td>\n",
       "      <td>[[the], [u], [s], [has], [said], [it], [will],...</td>\n",
       "      <td>[[the, u], [u, s], [s, has], [has, said], [sai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unofficial japanese estimates put the impact o...</td>\n",
       "      <td>[[unofficial], [japanese], [estimates], [put],...</td>\n",
       "      <td>[[unofficial, japanese], [japanese, estimates]...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sentences  \\\n",
       "0  asian exporters fear damage from u  s  japan r...   \n",
       "1  they told reuter correspondents in asian capit...   \n",
       "2  but some exporters said that while the conflic...   \n",
       "3  the u  s  has said it will impose  mln dlrs of...   \n",
       "4  unofficial japanese estimates put the impact o...   \n",
       "\n",
       "                                             unigram  \\\n",
       "0  [[asian], [exporters], [fear], [damage], [from...   \n",
       "1  [[they], [told], [reuter], [correspondents], [...   \n",
       "2  [[but], [some], [exporters], [said], [that], [...   \n",
       "3  [[the], [u], [s], [has], [said], [it], [will],...   \n",
       "4  [[unofficial], [japanese], [estimates], [put],...   \n",
       "\n",
       "                                              bigram  \n",
       "0  [[asian, exporters], [exporters, fear], [fear,...  \n",
       "1  [[they, told], [told, reuter], [reuter, corres...  \n",
       "2  [[but, some], [some, exporters], [exporters, s...  \n",
       "3  [[the, u], [u, s], [s, has], [has, said], [sai...  \n",
       "4  [[unofficial, japanese], [japanese, estimates]...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb45b56-6bd8-41ae-9c55-fb0343bbf32e",
   "metadata": {},
   "source": [
    "# Trigram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e36587d-6234-45fb-94e0-27cf15505d27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for defining the N-gram model\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Create a placeholder for model\n",
    "model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "# Count frequency of co-occurance  \n",
    "for i in range(dataset.shape[0]):\n",
    "    \n",
    "    # for each trigram pair\n",
    "    for w1, w2, w3 in create_trigram(dataset['Sentences'][i]):\n",
    "        \n",
    "        # count the occurance of word 3, given word 1 and word 2\n",
    "        model[(w1, w2)][w3] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5bf95f2-3d0a-4131-85ed-a58d143f2c02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'go': 1, 'have': 1, 'very': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(model[\"good\", \"to\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5331bb9-39fc-47bf-8d66-dd319763f66d",
   "metadata": {},
   "source": [
    "# Probablistic Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8483cd2d-fb2e-4e98-b7b8-1815fb3816ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 41244.97it/s]\n"
     ]
    }
   ],
   "source": [
    "unigram_dict = {}\n",
    "for i in tqdm(range(dataset.shape[0])):\n",
    "    \n",
    "    # add word-count pair to the dictionary\n",
    "    for word in dataset['unigram'][i]:   \n",
    "        \n",
    "        # check if the word is already in dictionary \n",
    "        if word[0] in unigram_dict:\n",
    "            \n",
    "            # increment count of word by 1 \n",
    "            unigram_dict[word[0]] = unigram_dict[word[0]] + 1\n",
    "        else:\n",
    "            # add the word to dictionary with count 1 \n",
    "            unigram_dict[word[0]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d886b70d-00b3-49ec-976a-1fedff8b01f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Counter(unigram_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99063689-3e4d-4713-a93d-e81a14a098db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12580"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocabulary size\n",
    "total_count = len(unigram_dict)\n",
    "total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc716ffa-12b1-4138-aa6c-4c2ff6f6d755",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in counts:\n",
    "    counts[word] /= float(total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90ad051f-19f5-4400-8a33-7c1cf0aec21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w1_w2 in model:\n",
    "    total_count = float(sum(model[w1_w2].values()))\n",
    "    for w3 in model[w1_w2]:\n",
    "        model[w1_w2][w3] /= total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4930875-c601-4b5c-a065-81416396d9a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pact': 0.0056179775280898875,\n",
       " 'surplus': 0.02247191011235955,\n",
       " 'marked': 0.011235955056179775,\n",
       " 'high': 0.016853932584269662,\n",
       " 'squeeze': 0.0056179775280898875,\n",
       " 'common': 0.0056179775280898875,\n",
       " 'record': 0.05056179775280899,\n",
       " 'calendar': 0.0056179775280898875,\n",
       " 'number': 0.02247191011235955,\n",
       " 'very': 0.028089887640449437,\n",
       " 'total': 0.033707865168539325,\n",
       " 'group': 0.033707865168539325,\n",
       " 'query': 0.016853932584269662,\n",
       " 'meeting': 0.0056179775280898875,\n",
       " 'gain': 0.0056179775280898875,\n",
       " 'buyer': 0.0056179775280898875,\n",
       " 'final': 0.0056179775280898875,\n",
       " 'rise': 0.0056179775280898875,\n",
       " 'message': 0.0056179775280898875,\n",
       " 'reporter': 0.0056179775280898875,\n",
       " 'to': 0.0056179775280898875,\n",
       " 'treasury': 0.0056179775280898875,\n",
       " 'decline': 0.011235955056179775,\n",
       " 'shortage': 0.0056179775280898875,\n",
       " 'pl': 0.0056179775280898875,\n",
       " 'more': 0.0056179775280898875,\n",
       " 'quick': 0.0056179775280898875,\n",
       " 'change': 0.0056179775280898875,\n",
       " 'maximum': 0.016853932584269662,\n",
       " 'seasonally': 0.02247191011235955,\n",
       " 'year': 0.033707865168539325,\n",
       " 'closer': 0.0056179775280898875,\n",
       " 'statement': 0.0056179775280898875,\n",
       " 'u': 0.0056179775280898875,\n",
       " 'market': 0.0056179775280898875,\n",
       " 'tax': 0.0056179775280898875,\n",
       " 'late': 0.0056179775280898875,\n",
       " 'sharp': 0.0056179775280898875,\n",
       " 'new': 0.016853932584269662,\n",
       " 'white': 0.011235955056179775,\n",
       " 'declared': 0.0056179775280898875,\n",
       " 'definitive': 0.0056179775280898875,\n",
       " 'weekly': 0.0056179775280898875,\n",
       " 'recession': 0.0056179775280898875,\n",
       " 'deterioration': 0.0056179775280898875,\n",
       " 'fall': 0.0056179775280898875,\n",
       " 'quasi': 0.011235955056179775,\n",
       " 'restructuring': 0.011235955056179775,\n",
       " 'billion': 0.011235955056179775,\n",
       " 'minimum': 0.0056179775280898875,\n",
       " 'sinking': 0.0056179775280898875,\n",
       " 'seasonal': 0.0056179775280898875,\n",
       " 'doubling': 0.0056179775280898875,\n",
       " 'return': 0.0056179775280898875,\n",
       " 'stable': 0.0056179775280898875,\n",
       " 'renewed': 0.0056179775280898875,\n",
       " 'price': 0.0056179775280898875,\n",
       " 'smaller': 0.0056179775280898875,\n",
       " 'pickup': 0.0056179775280898875,\n",
       " 'fiscal': 0.0056179775280898875,\n",
       " 'pct': 0.016853932584269662,\n",
       " 'local': 0.0056179775280898875,\n",
       " 'loss': 0.0056179775280898875,\n",
       " 'business': 0.011235955056179775,\n",
       " 'colombian': 0.0056179775280898875,\n",
       " 'study': 0.011235955056179775,\n",
       " 'published': 0.0056179775280898875,\n",
       " 'foreign': 0.0056179775280898875,\n",
       " 'solid': 0.0056179775280898875,\n",
       " 'firming': 0.0056179775280898875,\n",
       " 'fed': 0.0056179775280898875,\n",
       " 'dollar': 0.0056179775280898875,\n",
       " 'depth': 0.0056179775280898875,\n",
       " 'fixed': 0.0056179775280898875,\n",
       " 'fundamental': 0.0056179775280898875,\n",
       " 'physical': 0.0056179775280898875,\n",
       " 'financing': 0.0056179775280898875,\n",
       " 'merger': 0.0056179775280898875,\n",
       " 'falling': 0.0056179775280898875,\n",
       " 'finding': 0.0056179775280898875,\n",
       " 'hostile': 0.0056179775280898875,\n",
       " 'ten': 0.0056179775280898875,\n",
       " 'leveraged': 0.011235955056179775,\n",
       " 'share': 0.0056179775280898875,\n",
       " 'second': 0.0056179775280898875,\n",
       " 'lawsuit': 0.0056179775280898875,\n",
       " 'copy': 0.011235955056179775,\n",
       " 'clause': 0.0056179775280898875,\n",
       " 'provisional': 0.0056179775280898875,\n",
       " 'majority': 0.0056179775280898875,\n",
       " 'cut': 0.011235955056179775,\n",
       " 'round': 0.0056179775280898875,\n",
       " 'stock': 0.0056179775280898875,\n",
       " 'government': 0.0056179775280898875,\n",
       " 'risk': 0.0056179775280898875,\n",
       " 'package': 0.0056179775280898875,\n",
       " 'stronger': 0.0056179775280898875,\n",
       " 'plan': 0.0056179775280898875,\n",
       " 'third': 0.0056179775280898875,\n",
       " 'premium': 0.0056179775280898875,\n",
       " 'july': 0.0056179775280898875,\n",
       " 'trade': 0.0056179775280898875,\n",
       " 'range': 0.0056179775280898875,\n",
       " 'strong': 0.0056179775280898875,\n",
       " 'revised': 0.0056179775280898875,\n",
       " 'reduction': 0.0056179775280898875,\n",
       " 'particularly': 0.0056179775280898875,\n",
       " 'further': 0.0056179775280898875,\n",
       " 'newly': 0.0056179775280898875,\n",
       " 'management': 0.0056179775280898875,\n",
       " 'acre': 0.0056179775280898875,\n",
       " 'black': 0.0056179775280898875,\n",
       " 'surge': 0.0056179775280898875,\n",
       " 'large': 0.0056179775280898875,\n",
       " 'lesser': 0.0056179775280898875,\n",
       " 'resurgence': 0.0056179775280898875,\n",
       " 'miti': 0.0056179775280898875,\n",
       " 'trickle': 0.0056179775280898875,\n",
       " 'capacity': 0.0056179775280898875,\n",
       " 'spokeswoman': 0.0056179775280898875,\n",
       " 'nymex': 0.0056179775280898875}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(model[\"to\", \"a\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
