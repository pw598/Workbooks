{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0c21f64",
   "metadata": {},
   "source": [
    "# Spark ML Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7ff7fe",
   "metadata": {},
   "source": [
    "## Import Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e439b64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.types as tp\n",
    "from pyspark.sql import functions as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3df83370",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12e22998",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = spark.read.csv(\"train.csv\",inferSchema=True, header=True)\n",
    "test_data = spark.read.csv(\"test.csv\",inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58c55af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- User_ID: integer (nullable = true)\n",
      " |-- Product_ID: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Occupation: integer (nullable = true)\n",
      " |-- City_Category: string (nullable = true)\n",
      " |-- Stay_In_Current_City_Years: string (nullable = true)\n",
      " |-- Marital_Status: integer (nullable = true)\n",
      " |-- Product_Category_1: integer (nullable = true)\n",
      " |-- Product_Category_2: integer (nullable = true)\n",
      " |-- Product_Category_3: integer (nullable = true)\n",
      " |-- Purchase: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4589d1da",
   "metadata": {},
   "source": [
    "## 1. Calculate Average Purchase Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1aa6c308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>avg_purch</th></tr>\n",
       "<tr><td>9263.97</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------+\n",
       "|avg_purch|\n",
       "+---------+\n",
       "|  9263.97|\n",
       "+---------+"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.createOrReplaceTempView('train_data_view')\n",
    "\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select round(avg(Purchase),2) as avg_purch from train_data_view\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dad54b7",
   "metadata": {},
   "source": [
    "To validate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d198b326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    550068.000000\n",
       "mean       9263.968713\n",
       "std        5023.065394\n",
       "min          12.000000\n",
       "25%        5823.000000\n",
       "50%        8047.000000\n",
       "75%       12054.000000\n",
       "max       23961.000000\n",
       "Name: Purchase, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train_data.toPandas().describe()\n",
    "df['Purchase']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7915928e",
   "metadata": {},
   "source": [
    "The average purchase amount is $9263.97."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d341842",
   "metadata": {},
   "source": [
    "## 2. Count and Remove Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed037ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_ID 0\n",
      "Product_ID 0\n",
      "Gender 0\n",
      "Age 0\n",
      "Occupation 0\n",
      "City_Category 0\n",
      "Stay_In_Current_City_Years 0\n",
      "Marital_Status 0\n",
      "Product_Category_1 0\n",
      "Product_Category_2 173638\n",
      "Product_Category_3 383247\n",
      "Purchase 0\n"
     ]
    }
   ],
   "source": [
    "for c in train_data.columns:\n",
    "    missing_values = F.isnull(c)\n",
    "    missing_values = train_data.filter(missing_values).count()\n",
    "    print(c, missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8841221",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.fillna({\n",
    "            \"Product_Category_2\" : 0,\n",
    "            \"Product_Category_3\": 0\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97ba781c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product_Category_2 0\n",
      "Product_Category_3 0\n"
     ]
    }
   ],
   "source": [
    "for c in ['Product_Category_2', 'Product_Category_3']:\n",
    "    missing_values = F.isnull(c)\n",
    "    missing_values = train_data.filter(missing_values).count()\n",
    "    print(c, missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89260acc",
   "metadata": {},
   "source": [
    "## 3. Count Distinct Values per Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b87ad5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>User_ID</th><th>Product_ID</th><th>Gender</th><th>Age</th><th>Occupation</th><th>City_Category</th><th>Stay_In_Current_City_Years</th><th>Marital_Status</th><th>Product_Category_1</th><th>Product_Category_2</th><th>Product_Category_3</th><th>Purchase</th></tr>\n",
       "<tr><td>5891</td><td>3631</td><td>2</td><td>7</td><td>21</td><td>3</td><td>5</td><td>2</td><td>20</td><td>18</td><td>16</td><td>18105</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+----------+------+---+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
       "|User_ID|Product_ID|Gender|Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|\n",
       "+-------+----------+------+---+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
       "|   5891|      3631|     2|  7|        21|            3|                         5|             2|                20|                18|                16|   18105|\n",
       "+-------+----------+------+---+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, countDistinct\n",
    "train_data.agg(*(F.countDistinct(F.col(c)).alias(c) for c in train_data.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194d4cab",
   "metadata": {},
   "source": [
    "## 4. Count category values within each of the following columns:\n",
    "- Gender\n",
    "- Age\n",
    "- City_Category\n",
    "- Stay_In_Current_City_Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6daa8bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+\n",
      "|Gender|gender_count|\n",
      "+------+------------+\n",
      "|     F|      135809|\n",
      "|     M|      414259|\n",
      "+------+------------+\n",
      "\n",
      "+-----+---------+\n",
      "|  Age|age_count|\n",
      "+-----+---------+\n",
      "|18-25|    99660|\n",
      "|26-35|   219587|\n",
      "| 0-17|    15102|\n",
      "|46-50|    45701|\n",
      "|51-55|    38501|\n",
      "|36-45|   110013|\n",
      "|  55+|    21504|\n",
      "+-----+---------+\n",
      "\n",
      "+-------------+-------------+\n",
      "|City_Category|citycat_count|\n",
      "+-------------+-------------+\n",
      "|            B|       231173|\n",
      "|            C|       171175|\n",
      "|            A|       147720|\n",
      "+-------------+-------------+\n",
      "\n",
      "+--------------------------+-----------------+\n",
      "|Stay_In_Current_City_Years|stayinyears_count|\n",
      "+--------------------------+-----------------+\n",
      "|                         3|            95285|\n",
      "|                         0|            74398|\n",
      "|                        4+|            84726|\n",
      "|                         1|           193821|\n",
      "|                         2|           101838|\n",
      "+--------------------------+-----------------+\n",
      "\n",
      "+--------------+--------------------+\n",
      "|Marital_Status|marital_status_count|\n",
      "+--------------+--------------------+\n",
      "|             1|              225337|\n",
      "|             0|              324731|\n",
      "+--------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = train_data.groupBy(\"Gender\").agg(F.count(\"Gender\").alias(\"gender_count\"))\n",
    "df.show()\n",
    "\n",
    "df = train_data.groupBy(\"Age\").agg(F.count(\"Age\").alias(\"age_count\"))\n",
    "df.show()\n",
    "\n",
    "df = train_data.groupBy(\"City_Category\").agg(F.count(\"City_Category\").alias(\"citycat_count\"))\n",
    "df.show()\n",
    "\n",
    "df = train_data.groupBy(\"Stay_In_Current_City_Years\").agg(F.count(\"Stay_In_Current_City_Years\").alias(\"stayinyears_count\"))\n",
    "df.show()\n",
    "\n",
    "df = train_data.groupBy(\"Marital_Status\").agg(F.count(\"Marital_Status\").alias(\"marital_status_count\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad87cc5",
   "metadata": {},
   "source": [
    "## 5. Calculate average Purchase for each of the following columns:\n",
    "\n",
    "- Gender\n",
    "- Age\n",
    "- City_Category\n",
    "- Stay_In_Current_City_Years\n",
    "- Marital_Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d605927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+\n",
      "|Gender|avg_purch_by_gender|\n",
      "+------+-------------------+\n",
      "|     F|            8734.57|\n",
      "|     M|            9437.53|\n",
      "+------+-------------------+\n",
      "\n",
      "+-----+----------------+\n",
      "|  Age|avg_purch_by_age|\n",
      "+-----+----------------+\n",
      "|18-25|         9169.66|\n",
      "|26-35|         9252.69|\n",
      "| 0-17|         8933.46|\n",
      "|46-50|         9208.63|\n",
      "|51-55|         9534.81|\n",
      "|36-45|         9331.35|\n",
      "|  55+|         9336.28|\n",
      "+-----+----------------+\n",
      "\n",
      "+-------------+--------------------+\n",
      "|City_Category|avg_purch_by_citycat|\n",
      "+-------------+--------------------+\n",
      "|            B|              9151.3|\n",
      "|            C|             9719.92|\n",
      "|            A|             8911.94|\n",
      "+-------------+--------------------+\n",
      "\n",
      "+--------------------------+------------------------+\n",
      "|Stay_In_Current_City_Years|avg_purch_by_stayinyears|\n",
      "+--------------------------+------------------------+\n",
      "|                         3|                  9286.9|\n",
      "|                         0|                 9180.08|\n",
      "|                        4+|                  9275.6|\n",
      "|                         1|                 9250.15|\n",
      "|                         2|                 9320.43|\n",
      "+--------------------------+------------------------+\n",
      "\n",
      "+--------------+---------------------------+\n",
      "|Marital_Status|avg_purch_by_marital_status|\n",
      "+--------------+---------------------------+\n",
      "|             1|                    9261.17|\n",
      "|             0|                    9265.91|\n",
      "+--------------+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = train_data.groupBy(\"Gender\").agg(F.round(F.avg(\"Purchase\"),2).alias(\"avg_purch_by_gender\"))\n",
    "df.show()\n",
    "\n",
    "df = train_data.groupBy(\"Age\").agg(F.round(F.avg(\"Purchase\"),2).alias(\"avg_purch_by_age\"))\n",
    "df.show()\n",
    "\n",
    "df = train_data.groupBy(\"City_Category\").agg(F.round(F.avg(\"Purchase\"),2).alias(\"avg_purch_by_citycat\"))\n",
    "df.show()\n",
    "\n",
    "df = train_data.groupBy(\"Stay_In_Current_City_Years\").agg(F.round(F.avg(\"Purchase\"),2).alias(\"avg_purch_by_stayinyears\"))\n",
    "df.show()\n",
    "\n",
    "df = train_data.groupBy(\"Marital_Status\").agg(F.round(F.avg(\"Purchase\"),2).alias(\"avg_purch_by_marital_status\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab17718",
   "metadata": {},
   "source": [
    "Both item #6 and item #7 are addressed below:\n",
    "\n",
    "## 6. Label encode the following columns:\n",
    "- Age\n",
    "- Gender\n",
    "- Stay_In_Current_City_Years\n",
    "- City_Category\n",
    "\n",
    "## 7. One-Hot encode following columns:\n",
    "- Gender\n",
    "- City_Category\n",
    "- Occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0347500f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2acfb520",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_1 = StringIndexer(inputCol= 'Gender', outputCol= 'gender_le')\n",
    "stage_2 = StringIndexer(inputCol= 'City_Category', outputCol= 'citycat_le')\n",
    "stage_3 = StringIndexer(inputCol= 'Age', outputCol= 'age_le')\n",
    "stage_4 = StringIndexer(inputCol= 'Stay_In_Current_City_Years', outputCol= 'staycity_le')\n",
    "\n",
    "stage_5 = OneHotEncoderEstimator(inputCols= ['citycat_le', 'age_le', 'staycity_le', 'Product_Category_1', 'Occupation'], \n",
    "                                 outputCols= ['citycat_ohe', 'age_ohe', 'staycity_ohe', 'prodcat1_ohe', 'occupation_ohe'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0f0b65",
   "metadata": {},
   "source": [
    "## 8. Build a Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244721ec",
   "metadata": {},
   "source": [
    "### Vector Assembler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "816fdedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "550e0c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_6 = VectorAssembler(inputCols= [\"citycat_ohe\",\n",
    "                                      \"age_ohe\",\n",
    "                                      \"staycity_ohe\",\n",
    "                                      \"prodcat1_ohe\",\n",
    "                                      \"occupation_ohe\",\n",
    "                                      \"Marital_Status\"],\n",
    "\n",
    "                         outputCol=  \"feature_vector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0581a2db",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11b2934b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30bb0e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages= [stage_1,\n",
    "                             stage_2,\n",
    "                             stage_3,\n",
    "                             stage_4,\n",
    "                             stage_5,\n",
    "                             stage_6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96e26d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model = pipeline.fit(train_data)\n",
    "pipelined_data = pipeline_model.transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07694fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = regression.LinearRegression(featuresCol='feature_vector', labelCol=\"Purchase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d943d8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = lr.fit(pipelined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1aed0fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 3013.47\n",
      "r2: 0.6401\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator(labelCol=\"Purchase\", metricName=\"rmse\") \n",
    "mse = evaluator.evaluate(lr_model.transform(pipelined_data))\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"Purchase\", metricName=\"r2\") \n",
    "r2 = evaluator.evaluate(lr_model.transform(pipelined_data))\n",
    "\n",
    "print('mse:', round(mse,2))\n",
    "print('r2:', round(r2,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23af46e6",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "605fde7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0dc999d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = ParamGridBuilder().build()\n",
    "model = regression.LinearRegression(featuresCol= \"feature_vector\",  labelCol=\"Purchase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90df6270",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CrossValidator(estimator=model,\n",
    "                    estimatorParamMaps=params,\n",
    "                    evaluator=evaluator,\n",
    "                    numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab90dcc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6400869468327336"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_model = cv.fit(pipelined_data)\n",
    "evaluator.evaluate(cv_model.transform(pipelined_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f47e81",
   "metadata": {},
   "source": [
    "## 9. Model Improvement with Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f37b3764",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_params = ParamGridBuilder() \\\n",
    "                .addGrid(model.regParam, [0.1, 0.01, 0.001, 0.0001]) \\\n",
    "                .addGrid(model.elasticNetParam, [0.1, 0.01, 0.001, 0.0001]) \\\n",
    "                .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fb82fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CrossValidator(estimator=model,\n",
    "                    estimatorParamMaps=updated_params,\n",
    "                    evaluator=evaluator,\n",
    "                    numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51f030bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model = cv.fit(pipelined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75395a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2:  0.64005\n"
     ]
    }
   ],
   "source": [
    "print('r2: ', round(evaluator.evaluate(grid_model.transform(pipelined_data)),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e698b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN Param: 0.0001\n",
      "reg Param: 0.1\n"
     ]
    }
   ],
   "source": [
    "param_dict = grid_model.bestModel.extractParamMap()\n",
    "\n",
    "final_dict = {}\n",
    "for k, v in param_dict.items():\n",
    "    final_dict[k.name] = v\n",
    "    \n",
    "print('EN Param:', final_dict[\"elasticNetParam\"])\n",
    "print('reg Param:', final_dict[\"regParam\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd242ea",
   "metadata": {},
   "source": [
    "## RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c9ad307",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = regression.RandomForestRegressor(featuresCol='feature_vector', labelCol=\"Purchase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a9012495",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_params = ParamGridBuilder() \\\n",
    "                .addGrid(model.maxDepth, [5,10]) \\\n",
    "                .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f59ef4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2:  0.61067\n"
     ]
    }
   ],
   "source": [
    "cv = CrossValidator(estimator=model,\n",
    "                estimatorParamMaps=updated_params,\n",
    "                evaluator=evaluator,\n",
    "                numFolds=3)\n",
    "\n",
    "grid_model = cv.fit(pipelined_data)\n",
    "\n",
    "print('r2: ', round(evaluator.evaluate(grid_model.transform(pipelined_data)),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "171dfe86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: 10\n"
     ]
    }
   ],
   "source": [
    "param_dict = grid_model.bestModel.extractParamMap()\n",
    "\n",
    "final_dict = {}\n",
    "for k, v in param_dict.items():\n",
    "    final_dict[k.name] = v\n",
    "    \n",
    "print('Max Depth:', final_dict[\"maxDepth\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd69a9f",
   "metadata": {},
   "source": [
    "## 10. Create a Spark ML Pipeline for the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a47cdfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_1 = StringIndexer(inputCol= 'Gender', outputCol= 'gender_le')\n",
    "stage_2 = StringIndexer(inputCol= 'City_Category', outputCol= 'citycat_le')\n",
    "stage_3 = StringIndexer(inputCol= 'Age', outputCol= 'age_le')\n",
    "stage_4 = StringIndexer(inputCol= 'Stay_In_Current_City_Years', outputCol= 'staycity_le')\n",
    "\n",
    "stage_5 = OneHotEncoderEstimator(inputCols= ['citycat_le', 'age_le', 'staycity_le', 'Product_Category_1', 'Occupation'], \n",
    "                                 outputCols= ['citycat_ohe', 'age_ohe', 'staycity_ohe', 'prodcat1_ohe', 'occupation_ohe'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9c383bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_6 = VectorAssembler(inputCols= [\"citycat_ohe\",\n",
    "                                      \"age_ohe\",\n",
    "                                      \"staycity_ohe\",\n",
    "                                      \"prodcat1_ohe\",\n",
    "                                      \"occupation_ohe\",\n",
    "                                      \"Marital_Status\"],\n",
    "\n",
    "                         outputCol=  \"feature_vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bf84a8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage_7 = regression.RandomForestRegressor(featuresCol='feature_vector', labelCol=\"Purchase\",\n",
    "                                          maxDepth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "10ad8f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[stage_1, stage_2, stage_3, stage_4, stage_5, stage_6, stage_7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1d3de85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model = pipeline.fit(train_data)\n",
    "final_data = pipeline_model.transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6476d404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>prediction</th></tr>\n",
       "<tr><td>9174.276198602702</td></tr>\n",
       "<tr><td>13173.69040266748</td></tr>\n",
       "<tr><td>5413.292797433902</td></tr>\n",
       "<tr><td>5413.292797433902</td></tr>\n",
       "<tr><td>7299.575543295087</td></tr>\n",
       "<tr><td>13187.180790398652</td></tr>\n",
       "<tr><td>14397.232607365566</td></tr>\n",
       "<tr><td>14397.232607365566</td></tr>\n",
       "<tr><td>14397.232607365566</td></tr>\n",
       "<tr><td>7126.30062785148</td></tr>\n",
       "<tr><td>6202.029301621519</td></tr>\n",
       "<tr><td>7126.30062785148</td></tr>\n",
       "<tr><td>7126.30062785148</td></tr>\n",
       "<tr><td>13158.233846340652</td></tr>\n",
       "<tr><td>6440.1363159904395</td></tr>\n",
       "<tr><td>3677.956093398769</td></tr>\n",
       "<tr><td>11478.56415287904</td></tr>\n",
       "<tr><td>6440.1363159904395</td></tr>\n",
       "<tr><td>13369.492311919064</td></tr>\n",
       "<tr><td>14113.48800302702</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+------------------+\n",
       "|        prediction|\n",
       "+------------------+\n",
       "| 9174.276198602702|\n",
       "| 13173.69040266748|\n",
       "| 5413.292797433902|\n",
       "| 5413.292797433902|\n",
       "| 7299.575543295087|\n",
       "|13187.180790398652|\n",
       "|14397.232607365566|\n",
       "|14397.232607365566|\n",
       "|14397.232607365566|\n",
       "|  7126.30062785148|\n",
       "| 6202.029301621519|\n",
       "|  7126.30062785148|\n",
       "|  7126.30062785148|\n",
       "|13158.233846340652|\n",
       "|6440.1363159904395|\n",
       "| 3677.956093398769|\n",
       "| 11478.56415287904|\n",
       "|6440.1363159904395|\n",
       "|13369.492311919064|\n",
       "| 14113.48800302702|\n",
       "+------------------+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.select('prediction')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
